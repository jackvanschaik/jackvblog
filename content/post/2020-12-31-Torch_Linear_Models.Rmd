---
title: "Computing Batches of Linear Models with R Torch"
description: "Using R Torch's tensors to computer batches of beta coefficients"
date: 2020-12-31
categories: ["R", "Torch"]
tags: ["R Markdown", "R", "Torch", "Linear Models"]
twitterImg: images/clip.png
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
```

## Introduction

Earlier this year, the [Torch deep learning framework](https://blog.rstudio.com/2020/09/29/torch/) was made available for R. It works natively in R which is super exciting!

Underlying R Torch is tensors and the functions that operate on them. Tensors operations can be done by cpu, or an Nvidia GPU via CUDA. Upon entering [the R inferno](https://blog.rstudio.com/2020/09/29/torch/), you'll realize that matrices and matrix operations can be necessary for optimizing computation in R. Thus, the batch matrix operations enabled by R torch could be useful for anyone with a need for speed (especially if they have an Nvidia GPU).

I decided to test this out using on a familiar problem: linear models. The beta coefficients for a multiple linear regression are given by:

$(X^tX)^{-1}X^tY$

Where $X$ is the design matrix and $Y$ is the dependent variable. In multiple linear regression with $p$ predictors, there's $2^p$ possible models that can be created. For large $p$, it's computationally impractical to calculate every model, as the computational complexity is exponential with respect to $p$. For small enough $p$ however, it can sometime be desirable to calculate every possible model by brute force. This amounts to calculating $2^p$ matrix expressions in the form given above.

I decided to approach this with the batch tensor operation functions in R torch. I won't spend time on benchmarking as the point is really to explore how R torch can be used to approach problems like this. I'll use Torch to calculate the beta coefficients of a linear model on the familiar `iris` dataset.

## Set Up

Load R torch in:

```{r, warning=FALSE}
library(torch)
```
Set up some variables. `b` is the number of batches. We won't bother calculating the null model (intercept only). 

```{r}
X <- model.matrix(Sepal.Length ~ ., iris)
y <- iris$Sepal.Length

p <- ncol(X) - 1
N <- nrow(X)
b <- (2^p - 1)
```

We'll set up all our data in arrays, which we'll then convert to Torch tensors. 

Since we're using tensors to do batch matrix calculations, $X$ and $X^t$, should have consistent dimension. Naturally their dimension varies depending on the number of predictors, but we can perform the same calculations by making them submatrices of matrices with consistent dimension.

Notice the first dimension is always the batching dimension. 

```{r}
X_batch <- array(0, dim = c(b, N, p + 1))
Xt_batch <- array(0, dim = c(b, p + 1, N))
d_batch <- array(0, dim = c(b, p + 1, p + 1))
y_batch <- array(0, dim = c(b, N, N))

Id <- diag(p + 1)

for (j in 1:b) {
    cols <- c(1, bitwShiftR(j, 0:(p-1)) %% 2)
    diag(Id) <- cols
    sub_X <- X %*% Id
    diag(Id) <- as.numeric(!diag(Id))
    X_batch[j,,] <- sub_X
    Xt_batch[j,,] <- t(sub_X)
    d_batch[j,,] <- Id
    y_batch[j,,] <- diag(y)
}

```

## Computation

Now that we have batches of matrices stored in arrays, we can convert them to tensors and do our calculations.

We could set `device="cuda"` instead to do GPU based calculations.

Combined with the magrittr pipe (`%>%`), the batch matrix operations are pretty easy to look at. 

```{r}
X_tensor <- torch_tensor(X_batch)
Xt_tensor <- torch_tensor(Xt_batch)
d_batch <- torch_tensor(d_batch)
y_tensor <- torch_tensor(y_batch)

Xt_tensor %>%
    torch_bmm(X_tensor) %>%
    torch_add(d_batch) %>%
    torch_inverse %>%
    torch_bmm(Xt_tensor) %>%
    as.array %>%
    apply(1, `%*%`, matrix(y))

```
There we have it! Coefficients for every possible multiple linear regression model.

Just to check, let's compare against one of the actual linear models (for [,1]):

```{r}
lm(Sepal.Length ~ Sepal.Width, data=iris)
```
The coefficients match up!

## Conclusion

Torch is an exciting addition to R's data science ecosystem. Not only is it a powerful deep learning framework, the underlying tensor operations and GPU integration can provide a potential speed boost to other R tasks.

Thanks to everybody who worked on the R torch package!

## Session Info

```{r}
session_info()
```


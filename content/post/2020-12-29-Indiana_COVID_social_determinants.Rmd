---
title: "Dataset: Indiana COVID-19 and Social Determinants"
author: "Jack VanSchaik"
description: "A County Level COVID-19 and SDH dataset for Indiana"
date: 2020-12-29
categories: ["R", "COVID-19"]
tags: ["R Markdown", "R", "Indiana", "COVID-19", "Coronavirus", "Dataset"]
twitterImg: images/clip.png
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(message = FALSE)
```

## About

I created the following dataset for some coursework. It combines social determinants from the Census and COVID-19 outcomes from the Indiana government. 
The data is small, clean, normalized, and ready for analysis. You can run the code yourself or just copy the table at the bottom of the page. 

Each row in the dataset represents one county in Indiana, as indicated by the "location_id" and "county_name" columns. Note that column name prefixes indicate if the variable is an outcome or predictor. There are several outcome variables. All outcome variables have been normalized to count per 100k residents in the county. There are outcome variables for total cases and deaths during the entire span of the pandemic as well as three different "waves". These waves correspond to Indiana's back on track plan put in place by the state government, and it may be interesting to consider these seperately. 	

	
## Get Indiana COVID data from ISDH

#### Download Data

Can download via MPH's API

```{r}
library(tidycensus)
library(tidyverse)

mph_to_df <- function(resource_id) {
    url <- sprintf("https://hub.mph.in.gov/api/3/action/datastore_search?resource_id=%s&limit=1000000", resource_id)
    res <- jsonlite::fromJSON(url)$result
    janitor::clean_names(res$records)
}

# data taken from https://hub.mph.in.gov/dataset/covid-19-county-wide-test-case-and-death-trends
county_trends <- mph_to_df("afaa225d-ac4e-4e80-9190-f6800c366b58")
county_trends %>%
    mutate(
        county = as.character(location_id),
        date = as.Date(substr(date, 1, 10))
    ) ->
    county_trends

county_trends
```


## Get Social Determinants

#### Get initial list of social determinants

I created a list of census variables with the QUACS package. Looking at these, I further refined the list

```{r}
vars <- c(
    "B01003_001",
    "B01002_001",
    "B02001_001",
    "B02001_002",
    "B02001_003",
    "B02001_004",
    "B02001_005",
    "B02001_006",
    "B08135_001",
    "B19058_001",
    "B19058_003",
    "B19101_001",
    "B19101_002",
    "B19101_017",
    "B08301_001",
    "B08301_002",
    "B08301_010",
    "B08301_021",
    "B08303_001",
    "B08303_002",
    "B08303_013",
    "B14001_001",
    "B14001_002",
    "B17020_001",
    "B17020_002",
    "B19025_001",
    "B19058_001",
    "B19058_002",
    "B19083_001",
    "B19301_001",
    "B28010_001",
    "B28010_002"
)
```

Download the variables

```{r}
# You'll need your own API key here. I have mine saved to a file.
CENSUS_API_KEY <- readr::read_file("C:/Users/Jack/Documents/keys/census_api.txt")

acs_data <- get_acs(geography = "county", variables=vars, state="Indiana", key=CENSUS_API_KEY, cache_table=TRUE)
```

#### Normalize Variables

First, get a wide/ county level table of all variables

```{r}
v18 <- load_variables(2018, "acs5", cache = TRUE)

v18 %>% 
    filter(name %in% vars) %>%
    rename(variable=name) %>%
    right_join(acs_data, by="variable") %>%
    transmute(
        var_label = paste0(variable, "-", label),
        location_id=GEOID, estimate
    ) %>%
    pivot_wider(id_cols=location_id, names_from = "var_label", values_from="estimate") %>%
    janitor::clean_names() ->
    acs_data_2
```

Now, normalize by dividing by total population where necessary

```{r}
acs_data_2 %>%
    transmute(
        location_id,
        n_median_age = b01002_001_estimate_median_age_total,
        n_total_population = b01003_001_estimate_total,
        p_white = b02001_002_estimate_total_white_alone / b02001_001_estimate_total,
        p_black = b02001_003_estimate_total_black_or_african_american_alone / b02001_001_estimate_total,
        p_aian = b02001_004_estimate_total_american_indian_and_alaska_native_alone / b02001_001_estimate_total,
        p_asian = b02001_005_estimate_total_asian_alone / b02001_001_estimate_total,
        p_nhpi = b02001_006_estimate_total_native_hawaiian_and_other_pacific_islander_alone / b02001_001_estimate_total,
        n_avg_travel_per_person = b08135_001_estimate_aggregate_travel_time_to_work_in_minutes / b02001_001_estimate_total,
        n_total_households = b08301_001_estimate_total,
        p_automobile_commuters = b08301_002_estimate_total_car_truck_or_van / b08301_001_estimate_total,
        p_public_transpo = b08301_010_estimate_total_public_transportation_excluding_taxicab / b08301_001_estimate_total,
        p_public_work_from_home = b08301_021_estimate_total_worked_at_home / b08301_001_estimate_total,
        p_commute_len_less_than_5 = b08303_002_estimate_total_less_than_5_minutes / b08303_001_estimate_total,
        p_commute_len_more_than_90 = b08303_013_estimate_total_90_or_more_minutes / b08303_001_estimate_total,
        p_enrolled_in_school = b14001_002_estimate_total_enrolled_in_school / b14001_001_estimate_total,
        p_below_poverty_level = b17020_002_estimate_total_income_in_the_past_12_months_below_poverty_level / b17020_001_estimate_total,
        n_avg_agg_income = b19025_001_estimate_aggregate_household_income_in_the_past_12_months_in_2018_inflation_adjusted_dollars / b01003_001_estimate_total,
        p_snap_recipient = b19058_002_estimate_total_with_cash_public_assistance_or_food_stamps_snap / b19058_001_estimate_total,
        n_gini_index = b19083_001_estimate_gini_index,
        p_hh_income_less_than_10k = b19101_002_estimate_total_less_than_10_000 / b19101_001_estimate_total,
        p_hh_income_more_than_200k  = b19101_017_estimate_total_200_000_or_more / b19101_001_estimate_total,
        n_per_capita_income = b19301_001_estimate_per_capita_income_in_the_past_12_months_in_2018_inflation_adjusted_dollars,
        p_has_computers = b28010_002_estimate_total_has_one_or_more_types_of_computing_devices / b28010_001_estimate_total
    ) ->
    acs_data_3
```

## Create Outcome Variables

Now that we have a total population, we can aggregate and normalize counts and deaths by county.

I'll also divide the outcomes into three waves:

* Wave 1: Before July 4th, the originally planned date of stage 5
* Wave 2: From July 4th up until September 26, when stage 5 actually started
* Wave 3: September 26 until present

```{r}
acs_data_3 %>%
    select(location_id, n_total_population) ->
    total_pop

county_trends %>%
    group_by(location_id) %>%
    summarise(
        cases = sum(covid_count),
        deaths = sum(covid_deaths)
    ) %>%
    left_join(
        county_trends %>%
            group_by(location_id) %>%
            filter(date < as.Date("2020-07-04")) %>%
            summarise(
                cases_wave_1 = sum(covid_count),
                deaths_wave_1 = sum(covid_deaths)
            ), 
        by="location_id") %>%
    left_join(
        county_trends %>%
            group_by(location_id) %>%
            filter(date >= as.Date("2020-07-04") & date < as.Date("2020-09-26")) %>%
            summarise(
                cases_wave_2 = sum(covid_count),
                deaths_wave_2 = sum(covid_deaths)
            ),
        by="location_id"
    ) %>%
    left_join(
        county_trends %>%
            group_by(location_id) %>%
            filter(date >= as.Date("2020-09-26")) %>%
            summarise(
                cases_wave_3 = sum(covid_count),
                deaths_wave_3 = sum(covid_deaths)
            ),
        by="location_id"
    ) ->
    county_trends_2
```

```{r}
county_trends_2 %>%
    mutate(location_id = as.character(location_id)) %>%
    left_join(total_pop, by="location_id") %>%
    transmute(
        location_id,
        o_cases_per_100k = cases / (n_total_population / 100000),
        o_deaths_per_100k = deaths / (n_total_population / 100000),
        o_wave_1_cases_per_100k = cases_wave_1 / (n_total_population / 100000),
        o_wave_1_deaths_per_100k = deaths_wave_1 / (n_total_population / 100000),
        o_wave_2_cases_per_100k = cases_wave_2 / (n_total_population / 100000),
        o_wave_2_deaths_per_100k = deaths_wave_2 / (n_total_population / 100000),
        o_wave_3_cases_per_100k = cases_wave_3 / (n_total_population / 100000),
        o_wave_3_deaths_per_100k = deaths_wave_3 / (n_total_population / 100000)
    ) ->
    county_trends_3
```

## Create Final Dataset

Finally, combine predictors and outcomes

```{r}
county_trends %>%
    transmute(
        location_id = as.character(location_id), county_name
    ) %>%
    distinct %>%
    left_join(county_trends_3, by="location_id") %>%
    left_join(acs_data_3, by="location_id") %>%
    select(-n_total_population, -n_total_households) ->
    project_data
```

## Final Dataset

Here's the final dataset, printed out:

```{r}
knitr::kable(project_data)
```

## Session Info

```{r}
session_info()
```


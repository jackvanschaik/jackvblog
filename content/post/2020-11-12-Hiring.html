---
title: "Ethics of Workforce Analytics"
author: "Jack VanSchaik"
date: 2020-11-12
categories: ["Policy"]
tags: ["Policy", "Ethics"]
twitterImg: /images/clip.png
---

<script src="/rmarkdown-libs/header-attrs/header-attrs.js"></script>


<div id="some-thoughts-on-the-ethics-of-workforce-analytics" class="section level2">
<h2>Some Thoughts on the Ethics of Workforce Analytics</h2>
<p>Applying for jobs can be tedious and stressful for the applicant and hiring companies alike. Data driven workforce analytics attempts to solve this problem. Popular networking platform LinkedIn utilizes AI and data on a large, engaged used base to score and ultimately rank potential candidates for employers (Qi et al, 2019). Many other tools exist for employers to automate candidate selection, for example ZipRecruiter also uses AI and analysis of “millions of data points” (Enterprise FAQ, 2020). After a match online, candidates may additionally be vetted by employer-controlled workforce analytics packages such as Workforce Ready by KRONOS, which algorithmically automates parts of the approval process (Workforce Ready, 2020).</p>
<p>Much like educational technology, workforce analytics has ethical complications, such as the issue of autonomy. Due to algorithmically personalized notions of mutual interest, two similar candidates searching for the same job position may get different search results. Akin to issues in ed-tech, this “nudging” of candidates can be problematic if it leads to reduced welfare and is more acceptable if accompanied by some degree of transparency (Regan, P. M., &amp; Jesse, J. 2018). Additionally, the massive volume of data utilized by these tools can give the illusion of data objectivity, the idea that bias is mitigated by gathering enough information (Crawford, 2013). This can be especially appealing to companies that are held accountable by fairness in hiring laws such as Title VII, the Age Discrimination act, and others.</p>
<p>Massive data can massively embed bias. For example, LinkedIn trains its AI models by defining a successful match as one where an applicant positively responds to a message from an employer (Qi et al 2019). Unfortunately, employers may have biased in who they reached out to, potentially skewing any training data. Crawford, as well as Citron and Pasquale, offer oversight as a solution to some of these ethical issues (2014). While LinkedIn has taken some steps to be transparent about their algorithms, platforms do not make a point of openly explaining the scores that could keep somebody from their dream job. Private platforms like KRONOS can easily reject applicants without explanation, by using variables as surrogates for factors that would otherwise be illegal to discriminate against (O’neil, 2016), (Citron &amp; Pasquale, 2014).</p>
<p>In summary, AI and data reliant workforce analytics can save both applicants and employers time and help find a fulfilling match but are subject to some ethical challenges when job seekers are automatically scored and ranked.</p>
</div>
<div id="references" class="section level2">
<h2>References</h2>
<p>Citron, D. K., &amp; Pasquale, F. (2014). The scored society: Due process for automated predictions. Washington Law Review, 89, 1. <a href="https://heinonline.org/HOL/Page?handle=hein.journals/washlr89&amp;id=8&amp;div=&amp;collection=">https://heinonline.org/HOL/Page?handle=hein.journals/washlr89&amp;id=8&amp;div=&amp;collection=</a></p>
<p>Crawford, Kate. (Nov 8, 2013). Kate Crawford: Big Data Gets Personal. YouTube.
<a href="https://www.youtube.com/watch?v=JltwkXiBBTU&amp;feature=youtu.be">https://www.youtube.com/watch?v=JltwkXiBBTU&amp;feature=youtu.b</a></p>
<p>Enterprise FAQ. (2020) ZipRecruiter. <a href="https://www.ziprecruiter.com/enterprise_faq">https://www.ziprecruiter.com/enterprise_faq</a></p>
<p>O’neil, C. (2016). Weapons of math destruction: How big data increases inequality and threatens democracy. Broadway Books.</p>
<p>Qi Guo, Sahin Cem Geyik, Cagri Ozcaglar, Ketan Thakkar, Nadeem Anjum, and Krishnaram Kenthapadi. The AI Behind LinkedIn Recruiter search and recommendation systems. (April 22, 2019). LinkedIn Engineering. <a href="https://engineering.linkedin.com/blog/2019/04/ai-behind-linkedin-recruiter-search-and-recommendation-systems">https://engineering.linkedin.com/blog/2019/04/ai-behind-linkedin-recruiter-search-and-recommendation-systems</a></p>
<p>Regan, P. M., &amp; Jesse, J. (2018). Ethical challenges of edtech, big data and personalized learning: Twenty-first century student sorting and tracking. Ethics and Information Technology, 1–13. <a href="https://doi.org/10.1007/s10676-018-9492-2">https://doi.org/10.1007/s10676-018-9492-2</a></p>
<p>Workforce Ready. (2020). KRONOS. <a href="https://www.kronos.com/products/workforce-ready-suite">https://www.kronos.com/products/workforce-ready-suite</a></p>
</div>
<div id="footnote" class="section level2">
<h2>Footnote</h2>
<p>This essay was written for my Information Policy class as part of my Data Science PhD program at IUPUI. The essay has been published on my personal blog with the permission of the class instructor.</p>
</div>
